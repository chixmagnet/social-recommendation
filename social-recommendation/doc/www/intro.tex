Given the vast amount of content available on the Internet, finding
information of personal interest (news, blogs, videos, movies, books,
etc.) is often like finding a needle in a haystack.  Recommender
systems based on \emph{collaborative filtering}
(CF)~\cite{collab_filtering} aim to address this problem by leveraging
the preferences of a user population under the assumption that similar
users will have similar preferences.
%These principles underlie the
%recommendation algorithms powering websites like Amazon and
%Netflix.\footnote{On Amazon, this is directly evident with statements
%displayed of the form ``users who looked at item X ended up purchasing
%item Y 90\% of the time''.  While the exact inner workings of Netflix
%are not published, the best performing recommendation algorithm in
%the popular Netflix prize competition~\cite{netflix} 
%used an ensemble of CF methods.}

As the web has become more social with the emergence of Facebook,
Twitter, LinkedIn, and most recently Google+, this adds myriad new
dimensions to the recommendation problem by making available a rich
labeled graph structure of social content from which user preferences
can be learned and new recommendations can be made.  In this socially
connected setting, no longer are web users simply described by an IP
address (with perhaps associated geographical information and browsing
history), but rather they are described by a rich user profile (age,
gender, location, educational and work history, preferences, etc.)
and a rich history of user interactions with their friends (comments/posts, 
clicks of the like button, tagging in photos, mutual group
memberships, etc.).  This rich information poses both an amazing
opportunity and a daunting challenge for machine learning methods
applied to social recommendation --- how do we fully exploit rich social
network content in recommendation algorithms?

Many existing \emph{social CF} (SCF)
approaches~\cite{ste,sorec,lla,socinf,sr,rrmf} extend \emph{matrix
factorization} (MF) techniques such as~\cite{pmf} used
in the non-social CF setting.
These MF approaches have proved quite powerful and indeed, we will
show empirically in Section~\ref{sec:Baselines} that existing social
extensions of MF outperform a variety of other non-MF SCF baselines.  The
power of CF MF methods stems from their ability to project users
and items into latent vector spaces of reduced dimensionality where
each is effectively grouped by similarity; in turn, the power of many
of the SCF MF extensions stems
from their ability to use social network evidence to further
constrain (or regularize) latent user projections.

Given the strong performance of existing MF approaches to SCF, we aim
to further improve on their performance in this paper.  To do this, we
have first identified a number of major deficiencies of existing SCF MF
objective functions:
\begin{enumerate}
\item[(a)] {\bf Feature-based user similarity learning:} Existing SCF
MF objectives do not fully exploit user features when learning user
similarity based on observed interactions.  For example, one might 
enforce that two users are similar when their gender matches, but
existing SCF MF objectives do not allow \emph{learning} such a
property in cases where the data supports it.
% Note: potential for latent item information diffusion here
\item[(b)] {\bf Direct learning of user-to-user information
diffusion:} Existing SCF MF objectives do not permit directly modeling
user-to-user information diffusion according to the social graph
structure.  For example, if a certain user \emph{always} likes content
liked by a friend, this cannot be directly \emph{learned}
by optimizing existing SCF MF objectives.
\item[(c)] {\bf Learning restricted interests:} Existing SCF MF
objectives treat users as globally (dis)similar although they may only
be (dis)similar in specific latent areas of interest.  For example, a
friend and their co-worker may both like technology-oriented news
content, but have differing interests when it comes to
politically-oriented news content.  Existing SCF MF objective
functions do not leverage \emph{co-preference 
(dis)agreement} (i.e., whether two users agreed or disagreed in their
rating of the \emph{same} item) to encourage \emph{learning} restricted
latent areas where two users are (dis)similar.
\end{enumerate}

This paper addresses (a)--(c) by proposing novel objective functions
in a unified latent factorization framework for SCF.  We present
results of our proposed recommendation algorithms in online human
trials of a custom-developed Facebook App for link recommendation that
involves data collected over three months from over 100 active App
users and their 34,000+ friends.  These results show that the
extensions proposed to resolve (a)--(c) outperform a wide range of
previously existing SCF algorithms.

\COMMENT
On a final note, in order to evaluate a large number of SCF algorithms
as we do in this paper, it is important to identify offline evaluation
paradigms that correlate with actively elicited human judgments.  The
benefits of doing this are many-fold.  When designing new SCF
algorithms, there are myriad design choices to be made, for which
actual performance evaluation is the only way to validate the correct
choice.  Furthermore, simple parameter tuning is crucial for best
performance and SCF algorithms are often highly sensitive to
well-tuned parameters.  Thus for the purpose of algorithm design and
tuning, it is crucial to have methods and metrics that can be
evaluated offline on previously collected data (i.e., a data set of
user preferences for previous recommendations) that are shown to
correlate with human judgments in an online setting (where users
actively rate explicit recommendations) in order to avoid the
time-consuming process of evaluating the algorithms in live human
trials.  To this end, we identify train/test paradigms for the
ranking metric of \emph{mean average precision} (MAP)
that agree with online.
\ENDCOMMENT

To this end, the remaining sections of this paper are organized as follows:
\begin{itemize}
\item {\bf Section~\ref{sec:Background} -- Definitions and Background:} 
We define mathematical notation used throughout the paper along
with a discussion of related work and all baseline comparison methods
we use in this paper.
\item {\bf Section~\ref{sec:Background} -- New Objective Functions for
SCF:} We propose novel extensions to address (a)--(c) within a unified
mathematical framework and derive the formulae required to optimize them.
\item {\bf Section~\ref{sec:Evaluation} -- Evaluation Framework:} We
discuss the details of our Facebook App for link
recommendation as well as our evaluation methodology for both offline
and online (live user trial) experimentation.  
\COMMENT Our goal here
is to evaluate a variety of performance objectives, both qualitative
and quantitative, in order to evaluate the user experience with each
recommendation algorithm and to determine which online evaluations
correlate with which offline evaluations.  
\ENDCOMMENT
\item {\bf Section~\ref{sec:Baselines} -- Baselines:} We
identify MF-based SCF as the best-performing baseline algorithm in
our first online human evaluation trial.  Then we attempt to
identify the train/test paradigm and \emph{mean average precision}
(MAP) metric for offline evaluation that agrees the most with online
human feedback.  We later use this offline evaluation metric as a
surrogate for online human feedback evaluation in order to evaluate a
wide range of algorithm configurations that could not be evaluated
in online human trials due to limitations on the number of users and
the evaluation time.
\item {\bf Section~\ref{sec:NovelAlgs} -- New Objective Functions:}
Based on results from Section~\ref{sec:Baselines}, we choose a subset
of novel MF-based SCF objective function combinations from
Section~\ref{sec:Background} to evaluate in a second online human
evaluation trial.  After showing where each extension improves on the
baselines, we propose a number of additional hypotheses which we then
proceed to evaluate offline.
\item {\bf Section~\ref{sec:Conclusions} -- Conclusions:} We summarize
our conclusions from the empirical evaluations and outline directions
for future research.
% NOTE: one possible conclusion: beware of using passive evaluation 
%       metrics with inferred false labels.
\end{itemize}

All combined, this paper represents a critical step forward in
powerful SCF recommendation algorithms based on latent factorization
methods and their ability to fully exploit the breadth of information
available on social networks.
